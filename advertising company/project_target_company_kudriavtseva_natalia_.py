# -*- coding: utf-8 -*-
"""project_target_company_Kudriavtseva_Natalia .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iRZIk1bxXXSMPFqs_Mv824iWmHT7VVk7

**Analytical Task** -- to build a profile of a client inclined to a positive response to the advertising offer based on the feature description.

It is assumed that by obtaining such an assessment for a certain set of clients, the company will only approach those who are inclined to respond.

**Description of Fields**

|Feature|Decryption|
|--:|:--|
| AGREEMENT_RK | Unique identifier of the object in the sample |
| TARGET | Target variable: response to marketing campaign (1 - Response was recorded, 0 - No response was recorded) |
| AGE |	Customer's age|
| SOCSTATUS_WORK_FL | Customer's social status relative to employment (1 - employed, 0 - unemployed)|
| SOCSTATUS_PENS_FL | Customer's social status relative to pension (1 - pensioner, 0 - non-pensioner)|
| GENDER | Customer's gender |
| CHILD_TOTAL | Number of children of the client |
| DEPENDANTS | Number of dependents of the client|
| EDUCATION | Education |
| MARITAL_STATUS | Marital status |
| GEN_INDUSTRY | Customer's industry of work |
| GEN_TITLE |	Position or Job Title |
| ORG_TP_STATE |	Company ownership form |
| ORG_TP_FCAPITAL |	Attitude towards foreign capital|
| JOB_DIR |	Area of activity within the company|
| FAMILY_INCOME |	Family income (several categories)|
| PERSONAL_INCOME |	Client's personal income (in rubles)|
| REG_ADDRESS_PROVINCE | Customer's registration area|
| FACT_ADDRESS_PROVINCE | Customer's actual residence area|
| POSTAL_ADDRESS_PROVINCE |	Postal address region|
| TP_PROVINCE |	Region of the point of sale where the client last took out a loanт|
| REGION_NM	| Region |
| FL_PRESENCE_FL |Ownership of an apartment (1 - yes, 0 - no)|
| OWN_AUTO | Number of cars owned|
| AUTO_RUS_FL | Ownership of a Russian-made car (1 - yes, 0 - no)|
| HS_PRESENCE_FL |	Ownership of a country house (1 - yes, 0 - no)|
| COT_PRESENCE_FL |	Ownership of a cottage (1 - yes, 0 - no)|
| GAR_PRESENCE_FL |	Ownership of a garage (1 - yes, 0 - no)|
| LAND_PRESENCE_FL | Ownership of a land plot (1 - yes, 0 - no)|
| FACT_LIVING_TERM | Number of months lived at the actual residence area|
| WORK_TIME | Time working at the current job (in months)|
| CREDIT | Amount of the client's last loan (in rubles) |
| TERM | Loan term, months|
| LOAN_NUM_PAYM | Number of payments made by the client|
| LOAN_DLQ_NUM | Number of delays made by the client|
| LOAN_MAX_DLQ_AMT | Maximum overdue amount (in rubles)|
| DATE_CREDIT | Loan acquisition date |
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

import datetime as dt

df = pd.read_csv('/content/dataset_target_company.csv')
bank_df=df
bank_df

"""# Primary data preprocessing (if necessary):"""

bank_df.info()

"""- Checking for missing values in all columns"""

print(bank_df.isna().sum())
print(bank_df.isna().sum().sum())

for col in df.columns:
  pct_missing = np.mean(bank_df[col].isnull())
  print('{} - {}%'.format(col, round(pct_missing*100)))

def missing_summary_table(bank_df):
  miss_df = pd.concat([bank_df.isna().sum().to_frame(name = '1'),
                 np.round(bank_df.isna().mean().to_frame(name = '2')*100,
                          decimals = 2)],
                axis = 1).reset_index()
  miss_df.columns = ['Feature',
                     'Number of missing values',
                     'Percentage of missing values']
  miss_df.sort_values(by = 'Number of missing values',
                      ascending = False, inplace = True)
  miss_df['Percentage of missing values'] = (miss_df['Percentage of missing values'].
                                  map('{:,.2f}%'.format))
  return miss_df.style.set_caption('Summary table of missing values')

miss_table = missing_summary_table(df)
miss_table

colors = ['#000099', '#ffff00'] # yellow  - missing value, blue - not missing value
sns.heatmap(bank_df.isnull(), cmap=sns.color_palette(colors));

"""- Correct the headers:"""

bank_df.columns = bank_df.columns.str.lower()

bank_df.columns

"""- Restore missing values."""

#work_time: 1368, 8.99% - These values can possibly be restored by replacing missing values with the mean.
#gen_title: 1367, 8.98% - I don't see the point in restoring these data as they are strings, not integers. Losing 9% is not a significant loss.
#gen_industry: 1367, 8.98% - I don't see the point in restoring these data as they are strings, not integers. Losing 9% is not a significant loss.
#org_tp_state: 1367, 8.98% - I don't see the point in restoring these data as they are strings, not integers. Losing 9% is not a significant loss.
#org_tp_fcapital: 1365, 8.97% - I don't see the point in restoring these data as they are strings, not integers. Losing 9% is not a significant loss.
#tp_province: 295, 1.94% - Replace with the address from fact_address_province.
#region_nm: 1, 0.01% - Can be deleted without loss.

bank_df['work_time'].fillna(bank_df['work_time'].mean(),inplace = True)
bank_df.head(2)

#tp_province Restoration by replacing with the region from the fact address. fact_address_province
bank_df['tp_province'].fillna(bank_df['fact_address_province'],inplace = True)

bank_df.tp_province.unique()

# Convert to lowercase.
bank_df['education'] = bank_df['education'].str.lower()

bank_df.head(3)

"""- Checking for duplicate entries."""

#Handling duplicates.
bank_df.duplicated().sum()

#Deleting missing values 15223 / 13854 = 9% loss is not significant.

bank_df = bank_df.dropna()

bank_df.info()

#There are no anomalies in age (from 18 to 70).

bank_df['age'].agg(['min','max'])

"""
- Adjusting feature types; - not required
"""

bank_df.columns.unique()

"""- Checking for abnormal values;


"""

bank_df.info()

#Splitting features into continuous and categorical (discrete) features
var_cont = ['child_total', 'dependants', 'age',
            'personal_income', 'own_auto', 'fact_living_term',
            'work_time', 'credit', 'term',
            'loan_num_paym', 'loan_dlq_num', 'loan_max_dlq_amt']

dict_rus = {'child_total': 'Number of children of the client',
            'age': 'Age',
            'dependants': 'Number of dependents of the client',
            'personal_income': 'Personal income of the client (in rubles)',
            'own_auto': 'Number of cars owned by the client',
            'fact_living_term': 'Number of months lived at the actual residence area',
            'work_time': 'Time working at the current job (in months)',
            'credit': "Amount of the client's last loan (in rubles)",
            'term': 'Loan term, months',
            'loan_dlq_num': 'Number of delays made by the client',
            'loan_num_paym': 'Number of payments made by the client',
            'loan_max_dlq_amt': 'Maximum overdue amount (in rubles)'}

#Function to calculate lower and upper whiskers for a feature
def calc_boxplot(df_col : pd.Series) -> tuple:

    """

Function to calculate lower and upper whiskers.
Input: DataFrame column.
Output: Tuple where the first element is the lower whisker and the second element is the upper whisker.
    """

    Q1, median, Q3 = np.percentile(np.asarray(df_col.dropna()), [25, 50, 75])
    IQR = Q3 - Q1
    loval = Q1 - 1.5 * IQR
    hival = Q3 + 1.5 * IQR
    wiskhi = np.compress(np.asarray(df_col.dropna()) <= hival, np.asarray(df_col.dropna()))
    wisklo = np.compress(np.asarray(df_col.dropna()) >= loval, np.asarray(df_col.dropna()))
    actual_hival = np.max(wiskhi)
    actual_loval = np.min(wisklo)
    return actual_loval, actual_hival #(lower_whisker, upper_whisker)

fig, ax = plt.subplots(50, figsize = (40, 70))

for index, col in enumerate(var_cont):
  plt.subplot(12, 2, 2*index + 1)
  ax = sns.boxplot(data = bank_df , y = col, color= 'pink')
  ax.set_xlabel(dict_rus[col], fontsize = 15)

  ax.set_ylabel('Feature values <<{}>>'.format(dict_rus[col]),fontsize = 15)
  plt.title('Boxplot for the feature <<{}>>'.format(dict_rus[col], fontsize = 15))

  plt.subplot(12, 2, 2*index + 2 )
  ax = sns.distplot(bank_df[col],color= 'yellow');
  ax.set_xlabel(dict_rus[col],fontsize = 15)
  ax.set_ylabel('Density',fontsize = 15)
  plt.title('Density distribution of the feature <<{}>>'.format(dict_rus[col],fontsize = 15))
  ax.axvline(np.percentile(bank_df[col].dropna(), 1),
                    color = 'red',
                    label = 'Percentile 1 -- {}'.format(np.round(np.percentile(bank_df[col].dropna(), 1), 2)))
  ax.axvline(np.percentile(bank_df[col].dropna(), 5),
                    color = 'blue',
                    label = 'Percentile 5 -- {}'.format(np.round(np.percentile(bank_df[col].dropna(), 5), 2)))
  ax.axvline(np.percentile(bank_df[col].dropna(), 1),
                    color = 'yellow',
                    label = 'Percentile 95 -- {}'.format(np.round(np.percentile(bank_df[col].dropna(), 95), 2)))
  ax.axvline(np.percentile(bank_df[col].dropna(), 99),
                    color = 'green',
                    label = 'Percentile 99 -- {}'.format(np.round(np.percentile(bank_df[col].dropna(), 99), 2)))
  ax.axvline(calc_boxplot(bank_df[col])[0],
                    color = 'orange',
                    label = 'Lower whisker -- {}'.format(np.round(calc_boxplot(bank_df[col])[0], 2)))
  ax.axvline(calc_boxplot(bank_df[col])[1],
                    color ='red',
                    label = 'Upper whisker -- {}'.format(np.round(calc_boxplot(bank_df[col])[1], 2)))
  ax.axvline(bank_df[col].mean(),
                    color ='black',
                    label = 'Mean-- {}'.format(np.round(bank_df[col]).mean(), 2))
  ax.axvline(bank_df[col].median(),
                    color ='brown',
                    label = 'Median-- {}'.format(np.round(bank_df[col]).median(), 2))
  plt.tight_layout()

  plt.legend()
plt.show()

#10 children - seems like an anomaly, but theoretically it's possible. Decided to keep it.
bank_df['child_total'].agg(['min','max'])

#Didn't notice any significant anomalies, so I don't see the point in removing them.

from numpy.lib.function_base import percentile
# Searching for anomalous values

percentile = [0.01, 0.05, 0.25, 0.5, 0.75, 0.9 ,0.99]

bank_df.describe(percentiles = percentile)

var_cont = ['child_total', 'dependants', 'age',
            'personal_income', 'own_auto', 'fact_living_term',
            'work_time', 'credit', 'term',
            'loan_num_paym', 'loan_dlq_num', 'loan_max_dlq_amt']

"""# Adding the following features to the table:

- Day of the week, month, and year of taking the loan;

"""

#Let's separate the year.
bank_df['year'] = pd.DatetimeIndex(bank_df['date_credit']).year
#Let's separate the day.
bank_df['day'] = pd.DatetimeIndex(bank_df['date_credit']).day
#Let's separate the month.
bank_df['month'] = pd.DatetimeIndex(bank_df['date_credit']).month

bank_df

"""- Address of registration and address of actual residence of the client match (1 - matches, 0 - does not match)."""

#reg_address_province: Region of client's registration
#fact_address_province: Region of client's actual residence

#I'll write a loop and create a new column. 'address'
def categories(row):
  if row['reg_address_province'] == row['fact_address_province']:
    return 1
  elif row['reg_address_province']!= row['fact_address_province']:
    return 0

bank_df['address'] =bank_df.apply(lambda row : categories(row), axis =1)
bank_df.head(3)

#I'll check. ( 0; 1)
bank_df.address.unique()

"""-
The client's actual residence address and their mailing address match (1 - match, 0 - do not match)

"""

#postal_address_province: Province of the client's mailing address
#fact_address_province: Province of the client's actual residence

#I'll write a loop and create a new column 'address'
def categories(row):
  if row['postal_address_province'] == row['fact_address_province']:
    return 1
  elif row['postal_address_province']!= row['fact_address_province']:
    return 0

bank_df['postal'] =bank_df.apply(lambda row : categories(row), axis =1)
bank_df.head(3)

#I'll check. ( 0; 1)
bank_df.postal.unique()

"""- The client's registration address and postal address match (1 - match, 0 - do not match).

"""

#postal_address_province  postal address
 #reg_address_province    The province of the client's registration.

#I'll write a loop and create a new column'address'
def categories(row):
  if row['postal_address_province'] == row['reg_address_province']:
    return 1
  elif row['postal_address_province']!= row['reg_address_province']:
    return 0

bank_df['reg'] =bank_df.apply(lambda row : categories(row), axis =1)
bank_df.head(3)

#проверяемся ( 0; 1)
bank_df.reg.unique()

"""- Postal, actual, and registration addresses match (1 -- match, 0 -- no match).

"""

#postal_address_province  postal address
 #fact_address_province   The province of the client's actual residence

#I'll write a loop and create a new column'address'
def categories(row):
  if row['postal_address_province'] == row['fact_address_province']:
    return 1
  elif row['postal_address_province']!= row['fact_address_province']:
    return 0

bank_df['post_address'] =bank_df.apply(lambda row : categories(row), axis =1)
bank_df.head(3)

"""- Matching of the registration area, actual residence, postal address, and location area of the trading point where the client took the loan (1 -- match, 0 -- no match)."""

#postal_address_province: Province of the client's mailing address
#fact_address_province: Province of the client's actual residence
#reg_address_province: Province of the client's registration
#tp_province: Province of the location of the trade point

#I'll write a loop and create a new column 'address'
def categories(row):
  if row['postal_address_province'] == row['fact_address_province'] == row['reg_address_province'] == row['tp_province']:
    return 1
  elif row['postal_address_province']!= row['fact_address_province']:
    return 0
  elif row['postal_address_province']!= row['reg_address_province']:
    return 0
  elif row['postal_address_province']!= row['tp_province']:
    return 0

bank_df['all_cons'] =bank_df.apply(lambda row : categories(row), axis =1)
bank_df.head(3)

"""# Exploratory Data Analysis:

Investigate the dynamics of the number of loans over the years and months.
Explore numerical and categorical features in relation to the target feature.
Draw conclusions about the influence of features on the target feature.
"""

#Dynamics - plot the changes in variable values over time periods.
#Create groupings for categorical variables.
#Plot the number of observations and percentile for each value of the target variable.
test_df= bank_df

bank_df[['age', 'target']].agg(['mean', 'median']).round(1)

# It seems that the advertising is targeted at the average age of people with needs.

# The diagram shows that people reacted almost equally in all years.
disc_var = [ 'year','day', 'month', 'address','reg', 'post_address', 'post_address',
            'all_cons', 'gender', 'child_total',
            'dependants', 'target']

sns.countplot(data=bank_df, x='year', hue = 'target')

""" **1 -  Let's examine the relationship between all categorical features and the education level of clients. We may identify some dependencies.**"""

fig, ax = plt.subplots(5, figsize = (20,20))

for index, col in enumerate(disc_var, start = 1):
    plt.subplot(4, 3, index)
    sns.histplot(bank_df[bank_df.education == 'среднее специальное'][col].dropna(), kde = True, color = 'red')
    sns.histplot(bank_df[bank_df.education	 == 'среднее'][col].dropna(), kde = True, color = 'green')
    sns.histplot(bank_df[bank_df.education	 == 'неполное среднее'][col].dropna(), kde = True, color = 'blue')
    sns.histplot(bank_df[bank_df.education == 'высшее'][col].dropna(), kde = True, color = 'purple')
    sns.histplot(bank_df[bank_df.education == 'неоконченное высшее'][col].dropna(), kde = True, color = 'yellow')
    sns.histplot(bank_df[bank_df.education == 'два и более высших образования'][col].dropna(), kde = True, color = 'orange')
    sns.histplot(bank_df[bank_df.education == 'ученая степенья'][col].dropna(), kde = True, color = 'pink')
    #sns.histplot(df_eng[col], color = 'pink')

#We can see that in almost all categorical features, people with secondary vocational education (colleges and technical schools) are leading (1st place - secondary vocational, 2nd place - secondary, 3rd place - higher education).
#People with two or more higher educations and academic degrees are not as common, so comparing them doesn't make sense.
#Incomplete higher education is also worth paying attention to, as this category is also involved and shows responses to advertising and other categorical features.

"""**2 - Let's see how the advertising campaign performed in percentage terms.**"""

from plotly import graph_objects as go

fig = go.Figure(data = go.Pie( labels = df['target'].value_counts().reset_index()['index'], values = bank_df['target'].value_counts()))
fig.update_layout(
    title ={'text': 'The distribution of the "target" column in the advertisement.',
            'y': 0.9,
            'x':0.48}
)
for trace in fig.data:
  trace['labels']=['0 - No response', '1 - Response occurred']
fig.show()
print('The diagram shows that only 12.7% responded to the targeted advertisement.')

"""**3 - Let's look at the dependence of the categorical feature year/month/day on the number of clients over time.**"""

dict_to_rus = {
'year':'year',
'day':'day',
'month': 'month',

}

cat = ['year','day', 'month']
fig, axes = plt.subplots(3, sharey=True, figsize=(25,8))
i=0
for i, col in enumerate(cat):
    plt.subplot(1,3,i+1)
    sns.countplot(x=col, data=bank_df,)
    plt.title("Histogram \n for the feature <<{}>>".format(dict_to_rus[col]))
    plt.xlabel(dict_to_rus[col], fontsize = 12)
    plt.ylabel('Quantity', fontsize = 12)

#By grouping, it is evident that the highest number of loans were taken out in 2017, but overall the pace is good throughout the years, with the quantity fluctuating between 1750 and 2300.
#When analyzing by days, it's noticeable that the number of loans taken on the 31st is low, presumably due to not all months having 31 days in the calendar. However, there's a slight decrease towards the end of the month.
#When analyzing by months, decreases are observed in February (2nd), August (8th), October (10th), and December (12th). This is likely due to February having fewer days, and the other months being affected by pre-holiday periods or vacations often taken in August.

#It is necessary to determine the reasons and dependencies of the response.
#Let's test hypotheses.

disc_var1  = [ 'year','day', 'month','marital_status', 'gen_industry', 'gen_title', 'org_tp_state', 'org_tp_fcapital', 'job_dir', 'address','reg', 'post_address', 'post_address',
            'all_cons', 'gender', 'child_total','auto_rus_fl', 'fl_presence_fl',
            'dependants', 'target','land_presence_fl', 'gar_presence_fl','cot_presence_fl','hs_presence_fl','own_auto']

dict_to_rus1 = ({'year': 'year',
                 'day': 'day',
                 'month': 'month',
                 'marital_status': 'marital status',
                 'gen_industry': 'industry of client work',
                 'gen_title': 'position',
                 'org_tp_state': 'company ownership form',
                 'org_tp_fcapital': 'attitude to foreign capital',
                 'job_dir': 'direction of activity within the company',
                 'address': 'address of registration and actual residence of the client match (1 -- match, 0 -- do not match)',
                 'reg': 'actual residence address of the client and his postal address match (1 -- match, 0 -- do not match)',
                 'post_address': 'actual residence address of the client and his postal address match (1 -- match, 0 -- do not match)',
                 'all_cons': 'registration area, actual residence, postal address, and location of the sales point where the client took the loan match (1 -- match, 0 -- do not match)',
                 'gender': 'gender',
                 'fl_presence_fl': 'presence of an apartment in ownership (1 - yes, 0 - no)',
                 'auto_rus_fl': 'presence of a car of Russian production in ownership (1 - yes, 0 - no)',
                 'own_auto': 'number of cars in ownership',
                 'hs_presence_fl': 'presence of a country house in ownership (1 - yes, 0 - no)',
                 'cot_presence_fl': 'presence of a cottage in ownership (1 - yes, 0 - no)',
                 'gar_presence_fl': 'presence of a garage in ownership (1 - yes, 0 - no)',
                 'child_total': 'number of client children',
                 'land_presence_fl': 'presence of a land plot in ownership (1 - yes, 0 - no)',
                 'dependants': 'number of client dependents',
                 'target': 'target variable: response to marketing campaign (1 - response was registered, 0 - no response)'})

bank_df.columns

fig, axes = plt.subplots(13, sharey=True, figsize=(30,90))
fig.tight_layout (h_pad=20)
i=0
for i, col in enumerate(disc_var1):
  plt.subplot(13,2,i+1)
  data_all = bank_df[col].value_counts()
  r = (pd.DataFrame([bank_df[bank_df.target == 0][col].value_counts()/data_all,
  bank_df[bank_df.target == 1][col].value_counts()/data_all]).T)
  r.columns = ['0','1']
  ax1 = sns.barplot(x = r.index, y = r['0'], data = r, color='seagreen',
                    alpha = 0.5, label = 'No response')
  ax2 = sns.barplot(x = r.index, y = r['1'], data = r, color='blue',
                    alpha = 0.5, label = 'Response')
  plt.xticks(rotation = 45, fontsize = 14)
  plt.title("Feature «{}»".format(dict_to_rus1[col]), fontsize = 16)
  plt.ylabel('Proportion of clients', fontsize = 14)
  plt.legend()
for p in ax1.patches:
  x=p.get_bbox().get_points()[:,0]
  y=p.get_bbox().get_points()[1,1]
  ax1.annotate('{:.2f}%'.format(100*y),
   (x.mean(), y),ha='center', va='bottom', fontsize = 14)

"""**4 -Let's examine the dependencies of variable values on constants.**"""

# Let's look at the average amount of credit taken by clients before advertising and the average client's income (the data is small enough)
bank_df[['credit', 'personal_income']].agg(['mean', 'median']).round(1)

sns.histplot(x = bank_df['credit'],
             color = 'yellow',
             label = 'The previous loan',
             kde = True)
sns.histplot(x = bank_df['personal_income'],
             color = 'blue',
             label = 'Income',
             alpha = 0.3,
             kde = True)
plt.legend()

# It seems that there is a correlation between the income level and the previous loan amount, indicating that people take out loans based on their ability to repay them.

#Let's create a chart broken down by age
sns.pairplot(data = bank_df,
             vars = ['credit',
                     'personal_income'],
             hue = 'age')

#Let's create a chart broken down by target
sns.pairplot(data = bank_df,
             vars = ['credit',
                     'personal_income'],
             hue = 'target')

#We conclude that the advertising campaign performed better for a younger audience,
#as well as lower income and a smaller previous loan amount lead to another loan (targeted advertising works better).

"""#Ideal Customer Profile
For Future Target Marketing Company

- Male/Female sex in age 30-38 years
- Have children or dependents
- Married /living together / in divorce
- Have secondary or higher education
- To a greater extent to have an own car than not
- Work in marketing, real property area, business, entrepreneur. The area connects with internet
and very often to put attention on advertising
- Have experience to getting a credit before and clearly understand how they can pay in according to they income
- Without missing payment
- Work position as middle manager, private entrepreneur. Also it was reaction from military servicemen , obviously it depends on launched company before.
- Place of getting a credit is not depend on target and decision of acceptance . Target was good in Ulianovskiy region 50% and Mordovskay republic 39.5%
- Seasonal interest depends on days off, holidays and months. Be observed decrease in February , August , October, December.
- Response to the marketing target during 7 years show the stability result as13%

"""